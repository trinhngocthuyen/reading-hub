{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Probability\n",
    "https://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science/dp/1466575573\n",
    "\n",
    "## Chap 6. Moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terms/Highlights\n",
    "- If 2 normal distributions have the same values of $(\\mu, \\sigma^2)$. They are not necessarily the same (or even alike). In general, there could exist 2 different distributions that pretty differ each other but have the same parameters.\n",
    "\n",
    "- **Moments** are useful to describe what a distribution looks like including: mean, variance, symmetry, skewness, tails...\n",
    "  - *n*th ***moment***: $E(X^n)$\n",
    "  - *n*th ***central moment***: $E((X - \\mu)^n)$\n",
    "  - *n*th ***standardized moment***: $E\\left(\\left(\\frac{X - \\mu}{\\sigma}\\right)^n\\right)$\n",
    "\n",
    "- Usually use the first 4 moments:\n",
    "  - $E(X)$ = *1st moment*\n",
    "  - $Var(X) = E(X - \\mu)^2$ $\\rightarrow$ *2nd central moment*\n",
    "  - $Skew(X) = E\\left(\\frac{X - \\mu}{\\sigma}\\right)^3$ $\\rightarrow$ *3rd standardized moment*\n",
    "    - Describe the skewness of data\n",
    "    - $Skew(X) > 0$ means right-skewed\n",
    "  - $Kurt(X) = E\\left(\\frac{X = \\mu}{\\sigma}\\right)^4 - 3$ $\\rightarrow$ *4th standardized moment, (shifted)*\n",
    "    - Describe the tails of data\n",
    "    - Large $Kurt(X)$ means long tails\n",
    "\n",
    "- Looking at the PDF:\n",
    "  - **center**: the region $(\\mu - \\sigma, \\mu + \\sigma)$, within one standard deviation\n",
    "  - **shoulders**: the regions $(\\mu - 2\\sigma, \\mu - \\sigma)$ and $(\\mu + \\sigma, \\mu + 2\\sigma)$, from one standard deviation to 2 standard deviation\n",
    "  - **tails**: the regions $(-\\infty, \\mu - 2\\sigma)$ and $(\\mu + 2\\sigma, +\\infty)$, more than 2 standard deviations\n",
    "\n",
    "- Need to distinguish *sample parameters* from *population parameters*\n",
    "  - Sample mean: $\\bar{X}_n$, population mean: $\\mu$\n",
    "  - Law of large numbers: as $n \\to \\infty, \\bar{X}_n \\to \\mu$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Moment generating function (MGF)** of a r.v $X$ is $M(t) = E(e^{tX})$. Condition: $M(t)$ must be finite on some open interval $(-a, a)$ containing 0.\n",
    "  - Motivation: computing $E(X^n)$ by LOTUS is exhausting. MGF offers a nicer approach.\n",
    "  - Not all r.v.s have an MGF.\n",
    "\n",
    "- 3 important theorems related to MGF:\n",
    "  - *Theorem 1.* **Moments** via MGF: take the *n*th derivative of MGF, at 0\n",
    "    - $E(X^n) = M^{(n)}(0)$\n",
    "  - *Theorem 2.* MGF determines distribution\n",
    "    - $MGF(X) = MGF(Y) \\implies X = Y$\n",
    "  - *Theorem 3.* MGF of sum independent r.v.s\n",
    "    - $M_{X+Y}(t) = M_X(t) M_Y(t)$, if $X$ and $Y$ are independent of each other\n",
    "\n",
    "- Generating moments with MGFs\n",
    "  - Common technique: *expand the MGF and match the expression by taylor series.*<br>\n",
    "  For ex, if $M(t) = \\frac{1}{1-t}$, then:\n",
    "  $M(t) = \\sum\\limits^\\infty_{n=0} t^n = \\sum\\limits^\\infty_{n=0} n! \\frac{t^n}{n!}$<br>\n",
    "  And by Taylor series, $M(t) = \\sum\\limits^\\infty_{n=0} E(X^n) \\frac{t^n}{n!}$.<br>\n",
    "  Matching coefficients $\\implies$ $E(X^n) = n!$\n",
    "\n",
    "- Even if the MGF does not exist, we could probably obtain the moments. Computing Log-Normal moments is an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Probability generating function (MGF)** \n",
    "  - For non-negative integer-valued r.v X\n",
    "  - Given by $E(t^X)$\n",
    "- Relationship between PGF and MGF:\n",
    "  - $E(t^X) = E(e^{X \\log t})$, PGF is the MGF evaluated at $\\log t$\n",
    "  - Example of using PGF: generting dice probabilities (roll 6 dice, what is the prob. that the total values on all dice equal 18 = ?)\n",
    "\n",
    "- PGF determines the distribution\n",
    "- Recover distribution from the PGF $g_X(t)$ by $p_k = P(X=k) = \\frac{g_X^{(k)}(0)}{k!}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
